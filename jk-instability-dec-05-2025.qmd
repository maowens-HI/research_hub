---
title: "JK Instability"
date: "December 5, 2025"
format:
  html:
    toc: true
    toc-location: left
    toc-depth: 3
---

# Jackknife Classification Instability in Approach II

## Overview

This memo explains why the jackknife plots sometimes show the “high” group dipping below the “low” group. After applying the fixes Nick flagged on Tuesday, the updated charts look cleaner, but the same core issue remains: the jackknife estimates often compress the “high” group and, in several cases, push it below the “low” group.

The main mechanism is straightforward. Some counties that are classified as **low** in the full-sample prediction model (because predicted spending < 0) flip into the **high** category when their own state is excluded from the model during the jackknife procedure. This misclassification is likely not the only problem in the jackknife approach, but it appears to be a major contributor to the pattern we observe.

A closer investigation shows that **two states — Ohio and Texas** — have below-average spending growth among counties that should be in the highest-baseline-spending group. When these states are left out in the jackknife step, their influence disappears, and counties that underperform in the full sample suddenly receive inflated predicted spending values. This pushes them incorrectly into the “high predicted” category.

## Conceptual Setup

The goal is simple:  

1. Assign each county a predicted spending change.  
2. Create a binary indicator equal to 1 if predicted spending > 0 and 0 otherwise (for ever-treated counties).  
3. Run an event-study regression using that binary variable.

Under normal circumstances, this should yield the intuitive ordering: high above low.

## Two Ways to Generate Predicted Spending

### 1. Standard Regression

To keep things simple, consider the specification that controls only for baseline 1971 spending quartile. In the baseline approach, we use the full sample and regress expenditure on quartile indicators. This produces predicted spending values, which we then use to define `high` (predicted > 0). Running an event-study with this `high` variable delivers the expected pattern: **high consistently exceeds low**.

#### Figure 2.1: Spending Only (No Jackknife) {#fig-2-1}

![Event study estimates by baseline spending quartile](images/12_5_25/baseline_spec_A_def_A_high_vs_low.png){#fig-2-1-plot}

### 2. Jackknife (Leave-One-State-Out)

The jackknife repeats the same regression multiple times, each iteration excluding one state. For each iteration, we:

1. Re-estimate the model without state *s*.  
2. Generate predicted spending for counties in the omitted state.  
3. Assign those counties to high/low based on the jackknife prediction.  
4. Move on to the next state.

The advantage is that no single state can dominate the prediction model. The problem is that when we use these jackknife-based predictions to create the `high` variable for the second-stage event study, we sometimes obtain the reverse ordering: **the low group sits above the high group**.

#### Figure 2.2: Spending + Income Quartiles (No Jackknife) {#fig-2-2}

![Event study estimates by baseline spending and income quartiles](images/12_5_25/jackknife_spec_A_def_A_high_vs_low.png){#fig-2-2-plot}

Ordinarily I would assume this pattern reflects a coding mistake, because mechanically the high group should exceed the low group. But after checking the underlying data more closely, that explanation doesn’t hold.

Tabulating `pre_q × high` (baseline spending quartile × high/low classification) shows the issue clearly:

| Quartile  | Regular High | Jackknife High | Difference |
|-----------|--------------|----------------|------------|
| pre_q 1   | 3,080        | 3,080          | 0          |
| pre_q 2   | 3,136        | 3,136          | 0          |
| pre_q 3   | 0            | 504            | **+504**   |
| pre_q 4   | 0            | 336            | **+336**   |
| **Total** | 6,216        | 7,056          | **+840**   |

**Finding:** 840 counties from pre_q 3 and pre_q 4 (the highest-baseline-spending groups) switch from “low” to “high” under the jackknife. These are units that should theoretically have *lower* predicted spending changes, not higher.

---

## 3. Diagnosis

To understand the flips, we compare the coefficients that form predicted spending in the full sample versus the jackknife runs for Ohio and Texas. Predicted spending equals the main effect plus the quartile adjustment relative to quartile 1 (`main + ppe`). Here, `ppe3` and `ppe4` refer to the coefficients on `lag_*#pre_q3` and `lag_*#pre_q4`.

### Coefficients

**Full Sample**
- main = 0.0208505  
- ppe3 = −0.0227245  
- ppe4 = −0.0299217  

**Ohio Omitted**
- main = 0.0138311  
- ppe3 = −0.0193518  
- ppe4 = −0.0120878  

**Texas Omitted**
- main = 0.0248799  
- ppe3 = −0.0052331  
- ppe4 = −0.0299885  

### Interpretation

- When **Ohio** is excluded, `ppe4` rises from −0.0299217 to −0.0120878 (**+0.0178339**).  
  This boosts quartile-4 predicted spending enough to flip **336** quartile-4 counties into the high group.

- When **Texas** is excluded, `ppe3` rises from −0.0227245 to −0.0052331 (**~+0.0174914**).  
  This raises quartile-3 predicted spending, flipping **504** quartile-3 counties into the high group.

Together, these shifts generate **840** additional “high predicted” classifications that only appear under the jackknife. This inflates the size of the high group with counties that actually exhibit weak spending growth, which pulls down the average effect for the high group and produces the inversion seen in the jackknife plots.


 